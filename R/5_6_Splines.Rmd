---
title: "Splines"
output: html_notebook
---

## Exercise 1
In this exercise we'll consider regression splines, natural splines,
and smoothing splines. The Wage dataset from ISLR will be used.

1) Regression spline: Use the 'bs' function to fit a regressoin spline between wage and age
considering knots at 25, 40 and 60. Draw the regression line with the data.
Add lines for confidence intervals +- 2 standard error. How many basis
functions are used?

2) Use the 'df' and 'degree' arguments to specify a quadratic spline
regression with 6 degrees of freedom. Fit and display the model as per
(1). Where are the knots located?

3) Natural spline: Use the 'ns' function to fit a natural cubic spline with
6 degrees of freedom. Superimpose the line with that of (1). What is the
main comment you would make when comparing the models?

4) Smooth spline: Use the 'smooth.spline' function to fit a smoothing
spline to the data. Use the parameter df=16. Compare this to using
parameter cv=TRUE to use cross validation in the selection of the
optimal degree of freedom. Display both lines. What do the respective
models do?

--------------

## Solution

# 1
First we set up the model.
```{r}
library(ISLR)
data('Wage')
attach(Wage)

require(splines)

fit = lm(wage ~ bs(age, knots=c(25, 40, 60)), data=Wage)
```

Now we calculate predictions then plot the data and the line.
```{r}
# Set up 100 values in the range of age data
age_grid = seq(from=min(age), to=max(age), length=100)

pred = predict(fit, newdata=list(age=age_grid), se=TRUE)

plot(age, wage, col='gray')
lines(age_grid, pred$fit, lwd=2)
lines(age_grid, pred$fit + 2*pred$se, lty=2)
lines(age_grid, pred$fit - 2*pred$se, lty=2)
```

No answer RE number of basis functions. But the summary table below suggests 6.
```{r}
summary(fit)
```

# 2
We now fit a quadratic model setting df=6 and then plot the data and lines.
```{r}
fit2 = lm(wage ~ bs(age, df=6, degree=2), data=Wage)

pred2 = predict(fit2, newdata=list(age=age_grid), se=TRUE)

plot(age, wage, col='gray')
lines(age_grid, pred2$fit, lwd=2)
lines(age_grid, pred2$fit + 2*pred2$se, lty=2)
lines(age_grid, pred2$fit - 2*pred2$se, lty=2)
```

The following lists the knots.
```{r}
attr(bs(age, df=6, degree=2), 'knots')
```

# 3
Now we set up a 'natural' spline.
```{r}
fit3 = lm(wage ~ ns(age, df=6), data=Wage)

pred3 = predict(fit3, newdata=list(age=age_grid), se=TRUE)

plot(age, wage, col="gray", ylim=c(25, 200))
lines(age_grid, pred$fit, lwd=2)
lines(age_grid, pred$fit + 2*pred$se, lty=2)
lines(age_grid, pred$fit - 2*pred$se, lty=2)
lines(age_grid, pred3$fit, lwd=2, col="red")
lines(age_grid, pred3$fit + 2*pred3$se, lty=2, col="red")
lines(age_grid, pred3$fit - 2*pred3$se, lty=2, col="red")
legend(
  20, 200,
  legend=c('Regression spline', 'Natural spline'),
  col=c('black', 'red'),
  lty=1:1, cex=0.8
)
```

The main comment we can make is that the two models are very similar.
Variability at the edges is tighter for the natural spline.

# 4
Now we try a smooth spline under df=16, and then cv=TRUE.
```{r}
fit4 = smooth.spline(age, wage, df=16)
fit5 = smooth.spline(age, wage, cv=TRUE)

plot(age, wage, ylim=c(25,200), cex=0.5, col='darkgrey')
lines(fit4, col='black', lwd=2)
lines(fit5, col='red', lwd=2)
legend(
  20, 200,
  legend=c('Smooth (df=16)', 'Smooth (cv=TRUE'),
  col=c('black', 'red'),
  lty=1:1, cex=0.8
)

```

Let's see what the degree of freedom is for the CV model.
```{r}
fit5$df
```

When we specify df=16 the function determines which value
of lambda leads to 16 degrees of freedom. When we specify cv=TRUE
the function selects the smoothness level by cross validation.